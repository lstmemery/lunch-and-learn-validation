{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Validation: How to Know How Much Your Model Knows\n",
    "\n",
    "- Matthew Emery - Senior Data Scientist @ [Imbellus Inc.](https://www.imbellus.com/#/)\n",
    "- www.matthewemery.ca\n",
    "- Find the code at https://github.com/lstmemery/lunch-and-learn-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What Are We Covering?\n",
    "\n",
    " 1. A quick explainer on Fashion MNIST and Decision Trees\n",
    " 2. Overfitting Explanation\n",
    " 3. The Golden Rule of Machine Learning\n",
    " 4. Optimization Bias and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold\n",
    "from math import log, sqrt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import bokeh.plotting as bk\n",
    "import graphviz\n",
    "\n",
    "fmnist_class_names = [\"T-shirt\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "                    \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "with gzip.open(Path(\"data\", \"train-labels-idx1-ubyte.gz\")) as label_path:\n",
    "    labels = np.frombuffer(label_path.read(), dtype=np.uint8,\n",
    "                           offset=8)\n",
    "\n",
    "with gzip.open(Path(\"data\", \"train-images-idx3-ubyte.gz\")) as image_path:\n",
    "    features = np.frombuffer(image_path.read(), \n",
    "                           dtype=np.uint8, \n",
    "                           offset=16).reshape(len(labels), 784)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.matshow(features[0].reshape((28,28))) \n",
    "plt.title(\"Fashion MNIST Example\")\n",
    "plt.rcParams['figure.figsize'] = [50, 50]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- When I first wrote this tutorial, I used MNIST\n",
    "- Then I found out about Fashion MNIST\n",
    "- Benefits:\n",
    "    1. Harder than MNIST\n",
    "    2. Less used than MNIST\n",
    "    3. Better represents modern computer vision tasks\n",
    "- How many of you have heard of MNIST?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Quick Explainer on Decision Trees\n",
    "\n",
    "![](img/decision_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- A decision tree is trained by looking at each pixel value and seeing what breakpoint would split classes the best\n",
    "- Pick the best pixel to split on and continue\n",
    "- The size of the tree is a hyperparameter\n",
    "- I decided to choose a decision tree to illustrate this for a couple of reasons\n",
    "  1. Decision Trees are easy to understand\n",
    "  2. No need to do any preprocessing\n",
    "  3. It shows that even simple models can do simple computer vision tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train Test Split\n",
    "\n",
    "<img src=\"img/splitting-data.jpg\" alt=\"https://www.includehelp.com/ml-ai/data-splitting.aspx\" width=\"20%\" height=\"20%\" class=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "(train_features, validation_features,\n",
    " train_labels, validation_labels) = train_test_split(\n",
    "    features,\n",
    "    labels,\n",
    "    random_state=0,\n",
    "    shuffle=True,\n",
    "    test_size=0.20, # This is fine enough\n",
    "    stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- This is the core way we evaluate models\n",
    "- If we train on one dataset, how well does it do on the holdout?\n",
    "- Always set a seed so you can compare \n",
    "- Test size is traditionally 80/20 - this mostly folklore though\n",
    "- Do not shuffle if you are dealing with time series\n",
    "- Stratification is essential when you are dealing with unbalanced labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 1 Training Accuracy: 0.2\n",
      "Depth: 2 Training Accuracy: 0.36\n",
      "Depth: 3 Training Accuracy: 0.5\n",
      "Depth: 4 Training Accuracy: 0.65\n",
      "Depth: 5 Training Accuracy: 0.71\n",
      "Depth: 6 Training Accuracy: 0.74\n",
      "Depth: 7 Training Accuracy: 0.78\n",
      "Depth: 8 Training Accuracy: 0.81\n",
      "Depth: 9 Training Accuracy: 0.83\n",
      "Depth: 10 Training Accuracy: 0.85\n",
      "Depth: 11 Training Accuracy: 0.87\n",
      "Depth: 12 Training Accuracy: 0.89\n",
      "Depth: 13 Training Accuracy: 0.91\n",
      "Depth: 14 Training Accuracy: 0.93\n",
      "Depth: 15 Training Accuracy: 0.94\n",
      "Depth: 16 Training Accuracy: 0.96\n",
      "Depth: 17 Training Accuracy: 0.97\n",
      "Depth: 18 Training Accuracy: 0.98\n",
      "Depth: 19 Training Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "models, train_scores = [], []\n",
    "\n",
    "for depth in range(1, 20):\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state=0)\n",
    "    model.fit(train_features, train_labels)\n",
    "    \n",
    "    score = model.score(train_features, train_labels)\n",
    "    print(\"Depth:\", depth, \"Training Accuracy:\", round(score, 2))\n",
    "    models.append(model); train_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img/decision_tree.png'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how the first Decision Tree Illustration Was Made\n",
    "graph_data = export_graphviz(models[1],\n",
    "                            filled=True,\n",
    "                            rounded=True,\n",
    "                            class_names=fmnist_class_names)\n",
    "graph = graphviz.Source(graph_data, format=\"png\")\n",
    "graph.render(\"decision_tree\", \"img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 0 Validation Accuracy: 0.2\n",
      "Depth: 1 Validation Accuracy: 0.36\n",
      "Depth: 2 Validation Accuracy: 0.5\n",
      "Depth: 3 Validation Accuracy: 0.65\n",
      "Depth: 4 Validation Accuracy: 0.71\n",
      "Depth: 5 Validation Accuracy: 0.73\n",
      "Depth: 6 Validation Accuracy: 0.76\n",
      "Depth: 7 Validation Accuracy: 0.78\n",
      "Depth: 8 Validation Accuracy: 0.8\n",
      "Depth: 9 Validation Accuracy: 0.81\n",
      "Depth: 10 Validation Accuracy: 0.81\n",
      "Depth: 11 Validation Accuracy: 0.81\n",
      "Depth: 12 Validation Accuracy: 0.82\n",
      "Depth: 13 Validation Accuracy: 0.81\n",
      "Depth: 14 Validation Accuracy: 0.81\n",
      "Depth: 15 Validation Accuracy: 0.81\n",
      "Depth: 16 Validation Accuracy: 0.81\n",
      "Depth: 17 Validation Accuracy: 0.81\n",
      "Depth: 18 Validation Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "validation_scores = []\n",
    "\n",
    "for depth, model in enumerate(models):\n",
    "    score = model.score(validation_features, validation_labels)\n",
    "    print(\"Depth:\", depth, \"Validation Accuracy:\", round(score, 2))\n",
    "    validation_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_1 = bk.figure(title=\"Training vs. Validation Accuracy\",\n",
    "    )\n",
    "plot_1.xaxis.axis_label = \"Depth\"\n",
    "plot_1.yaxis.axis_label = \"Accruacy\"\n",
    "plot_1.line(x = range(1, 20), y = train_scores, \n",
    "            line_width = 5, color = \"blue\", legend = \"Training Accuracy\")\n",
    "plot_1.line(x = range(1, 20), y = validation_scores, \n",
    "            line_width = 5, color = \"orange\", legend = \"Validation Accuracy\")\n",
    "bk.show(plot_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](img/bokeh_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    " - If you want to show Bokeh plots inline you need\n",
    "\n",
    "`jupyter labextension install jupyterlab_bokeh`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overfitting\n",
    "\n",
    "- The gap between training and validation accuracy is **overfitting**\n",
    " - **Interpretation**: Our model has memorized part of the data set instead of learning the underlying rules\n",
    " - If the validation accuracy was higher than our training that's **underfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Think About Studying for an Exam\n",
    "\n",
    "- Training your model is like the model reviewing its notes\n",
    "- Validating your model is when you take the midterm\n",
    "- Deploying your model is the final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Golden Rule of Machine Learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# The test cannot influence training in any way\n",
    "\n",
    "- If you know the answers on the exam ahead of time, you won't know if you actually learned the material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Common Mistakes\n",
    "\n",
    " - Time Series: Incorporating information from the future in your model (i.e., quarterly results before end-of-quarter)\n",
    " - Imputing based on the combined train-test dataset\n",
    " - Taking a peek on the test data halfway through training your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Should I Just Fit a Million Models Until I Find Something?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# No!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## An Illustration\n",
    "\n",
    "\n",
    " - Sign up for my service, and I'll email you a prediction of whether or not the S&P 500 goes up or down that morning\n",
    " - Every work day for two weeks I'm right\n",
    " - **What do you need to ask me before you should trust my model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How Many Other People Did I Send Emails To?\n",
    "\n",
    "- Two business weeks is 10 business days\n",
    "$$2^{10} = 1024$$\n",
    "- If I sent 1024 people different emails (Up, Down, Up, etc.) I'm guaranteed to be right once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Same Thing Happens with Machine Learning Models\n",
    "\n",
    " - We call this **optimization bias**\n",
    " - Sometimes you find something that fits your validation data set through dumb luck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How Do We Decrease the Effect of Optimization Bias?\n",
    "\n",
    "- **Cross-validation** (or repeated cross-validation)\n",
    "- Leave a **test set** that you evaluate very rarely (once a week or less)\n",
    "- Set a limit to the number of models you will evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "![https://bradleyboehmke.github.io/hands-on-machine-learning-with-r/regression-performance.html](img/cross-validation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 1 Mean: 0.2 SD: 0.0\n",
      "Depth: 2 Mean: 0.36 SD: 0.002\n",
      "Depth: 3 Mean: 0.5 SD: 0.003\n",
      "Depth: 4 Mean: 0.65 SD: 0.002\n",
      "Depth: 5 Mean: 0.71 SD: 0.003\n",
      "Depth: 6 Mean: 0.73 SD: 0.003\n",
      "Depth: 7 Mean: 0.76 SD: 0.003\n",
      "Depth: 8 Mean: 0.79 SD: 0.002\n",
      "Depth: 9 Mean: 0.8 SD: 0.002\n",
      "Depth: 10 Mean: 0.81 SD: 0.003\n",
      "Depth: 11 Mean: 0.81 SD: 0.004\n",
      "Depth: 12 Mean: 0.81 SD: 0.003\n",
      "Depth: 13 Mean: 0.81 SD: 0.003\n",
      "Depth: 14 Mean: 0.81 SD: 0.002\n",
      "Depth: 15 Mean: 0.81 SD: 0.003\n",
      "Depth: 16 Mean: 0.81 SD: 0.004\n",
      "Depth: 17 Mean: 0.81 SD: 0.004\n",
      "Depth: 18 Mean: 0.81 SD: 0.004\n",
      "Depth: 19 Mean: 0.81 SD: 0.005\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "for depth in range(1, 20):\n",
    "    model = DecisionTreeClassifier(\n",
    "        max_depth=depth,\n",
    "    random_state=0)\n",
    "    \n",
    "    cv_score = cross_val_score(\n",
    "        model,\n",
    "        features,\n",
    "        labels,\n",
    "        cv = 5,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    \n",
    "    print(\"Depth:\", depth,\n",
    "          \"Mean:\", round(np.mean(cv_score), 2), \n",
    "          \"SD:\", round(np.std(cv_score), 3))\n",
    "    \n",
    "    cv_scores.append(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_2 = plot_1\n",
    "\n",
    "plot_2.line(x = range(1, 20), y = np.mean(cv_scores, axis=-1), \n",
    "            line_width = 5, color = \"purple\", legend = \"Cross Validation Accuracy\")\n",
    "bk.show(plot_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](img/bokeh_plot_cv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Notice that this doesn't change much\n",
    "- This is because we already have sufficient data to get an accurate result\n",
    "- Try this on a smaller dataset\n",
    "- This is good news, cross-validation takes longer than validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    " - Always create a validation set (cross-validation if you have a small amount of data)\n",
    " - Never let information from your validation set leak into to your training\n",
    " - Don't train models for no reason"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bibliography\n",
    "\n",
    "\n",
    "[1] “Data splitting | Machine Learning.” [Online]. Available: https://www.includehelp.com/ml-ai/data-splitting.aspx. [Accessed: 17-Mar-2019].\n",
    "\n",
    "[2]“1.10. Decision Trees — scikit-learn 0.20.3 documentation.” [Online]. Available: https://scikit-learn.org/stable/modules/tree.html#tree. [Accessed: 17-Mar-2019].\n",
    "\n",
    "[3]M. Schmidt, “DSCI 573: Model Selection and Feature Selection 1.”\n",
    "\n",
    "[4]T. Sarkar, “How to analyze ‘Learning’: Short tour of computational learning theory,” Towards Data Science, 26-Oct-2018. [Online]. Available: https://towardsdatascience.com/how-to-analyze-learning-short-tour-of-computational-learning-theory-9d93b15fc3e5. [Accessed: 03-Mar-2019].\n",
    "\n",
    "[5]A MNIST-like fashion product database. Benchmark :point_right: : zalandoresearch/fashion-mnist. Zalando Research, 2019.\n",
    "\n",
    "[6]I. Guyon and T. B. Laboratories, “A scaling law for the validation-set training-set size ratio,” p. 11."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
